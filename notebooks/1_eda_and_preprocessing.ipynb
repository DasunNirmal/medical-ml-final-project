{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "149643a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# For model persistence\n",
    "import joblib\n",
    "\n",
    "# For loading dataset from Hugging Face\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(\"✅ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fd0b7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Medical Cases Classification Dataset from Hugging Face...\n",
      "This may take 1-2 minutes on first run (downloading ~50MB)...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset loaded successfully!\n",
      "Training samples: 1724\n",
      "Validation samples: 370\n",
      "Test samples: 370\n",
      "Total samples: 2464\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Medical Cases Classification Dataset from Hugging Face...\")\n",
    "print(\"This may take 1-2 minutes on first run (downloading ~50MB)...\\n\")\n",
    "\n",
    "# Load dataset (pre-split into train/validation/test)\n",
    "dataset = load_dataset(\"hpe-ai/medical-cases-classification-tutorial\")\n",
    "\n",
    "# Convert to pandas DataFrames for easier manipulation\n",
    "train_df = pd.DataFrame(dataset['train'])\n",
    "val_df = pd.DataFrame(dataset['validation'])\n",
    "test_df = pd.DataFrame(dataset['test'])\n",
    "\n",
    "print(\"✅ Dataset loaded successfully!\")\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "print(f\"Total samples: {len(train_df) + len(val_df) + len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9ba713",
   "metadata": {},
   "source": [
    "## Load the Medical Dataset\n",
    "<!-- Purpose: Download and load the medical transcription dataset from Hugging Face\n",
    "The dataset contains 2,460 medical case transcriptions across 13 specialties -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae62fd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DATASET STRUCTURE OVERVIEW\n",
      "======================================================================\n",
      "\n",
      "Dataset shape: (1724, 5)\n",
      "Number of features: 5\n",
      "Feature names: ['description', 'transcription', 'sample_name', 'medical_specialty', 'keywords']\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "First 3 samples:\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>transcription</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pacemaker ICD interrogation.  Severe nonischem...</td>\n",
       "      <td>PROCEDURE NOTE: , Pacemaker ICD interrogation....</td>\n",
       "      <td>Pacemaker Interrogation</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>cardiovascular / pulmonary, cardiomyopathy, ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Erythema of the right knee and leg, possible s...</td>\n",
       "      <td>PREOPERATIVE DIAGNOSES: , Erythema of the righ...</td>\n",
       "      <td>Aspiration - Knee Joint</td>\n",
       "      <td>Orthopedic</td>\n",
       "      <td>orthopedic, knee and leg, anterolateral portal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Left cardiac catheterization with selective ri...</td>\n",
       "      <td>PREOPERATIVE DIAGNOSIS: , Post infarct angina....</td>\n",
       "      <td>Cardiac Cath &amp; Selective Coronary Angiography</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>cardiovascular / pulmonary, selective, angiogr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0  Pacemaker ICD interrogation.  Severe nonischem...   \n",
       "1  Erythema of the right knee and leg, possible s...   \n",
       "2  Left cardiac catheterization with selective ri...   \n",
       "\n",
       "                                       transcription  \\\n",
       "0  PROCEDURE NOTE: , Pacemaker ICD interrogation....   \n",
       "1  PREOPERATIVE DIAGNOSES: , Erythema of the righ...   \n",
       "2  PREOPERATIVE DIAGNOSIS: , Post infarct angina....   \n",
       "\n",
       "                                     sample_name           medical_specialty  \\\n",
       "0                        Pacemaker Interrogation  Cardiovascular / Pulmonary   \n",
       "1                        Aspiration - Knee Joint                  Orthopedic   \n",
       "2  Cardiac Cath & Selective Coronary Angiography  Cardiovascular / Pulmonary   \n",
       "\n",
       "                                            keywords  \n",
       "0  cardiovascular / pulmonary, cardiomyopathy, ve...  \n",
       "1  orthopedic, knee and leg, anterolateral portal...  \n",
       "2  cardiovascular / pulmonary, selective, angiogr...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Dataset Information:\n",
      "----------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1724 entries, 0 to 1723\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   description        1724 non-null   object\n",
      " 1   transcription      1724 non-null   object\n",
      " 2   sample_name        1724 non-null   object\n",
      " 3   medical_specialty  1724 non-null   object\n",
      " 4   keywords           1109 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 67.5+ KB\n",
      "None\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Missing Values Check:\n",
      "----------------------------------------------------------------------\n",
      "description            0\n",
      "transcription          0\n",
      "sample_name            0\n",
      "medical_specialty      0\n",
      "keywords             615\n",
      "dtype: int64\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Basic Statistics:\n",
      "----------------------------------------------------------------------\n",
      "                                              description  \\\n",
      "count                                                1724   \n",
      "unique                                               1259   \n",
      "top     MRI T-L spine - L2 conus medullaris lesion and...   \n",
      "freq                                                    5   \n",
      "\n",
      "                                            transcription  \\\n",
      "count                                                1724   \n",
      "unique                                               1263   \n",
      "top     CC: ,Paraplegia.,HX:, This 32 y/o RHF had been...   \n",
      "freq                                                    5   \n",
      "\n",
      "                    sample_name           medical_specialty  \\\n",
      "count                      1724                        1724   \n",
      "unique                     1294                          13   \n",
      "top     Neuroblastoma - Consult  Cardiovascular / Pulmonary   \n",
      "freq                          5                         526   \n",
      "\n",
      "                                                 keywords  \n",
      "count                                                1109  \n",
      "unique                                                971  \n",
      "top     cardiovascular / pulmonary, thrombosed, hyperk...  \n",
      "freq                                                    2  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATASET STRUCTURE OVERVIEW\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nDataset shape: {train_df.shape}\")\n",
    "print(f\"Number of features: {train_df.shape[1]}\")\n",
    "print(f\"Feature names: {list(train_df.columns)}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"First 3 samples:\")\n",
    "print(\"-\"*70)\n",
    "display(train_df.head(3))\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Dataset Information:\")\n",
    "print(\"-\"*70)\n",
    "print(train_df.info())\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Missing Values Check:\")\n",
    "print(\"-\"*70)\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Basic Statistics:\")\n",
    "print(\"-\"*70)\n",
    "print(train_df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eb14fd",
   "metadata": {},
   "source": [
    "## Initial Data Exploration\n",
    "<!-- Purpose: Understand the structure and content of the dataset -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3c66ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TEXT LENGTH ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Character Length Statistics:\n",
      "----------------------------------------------------------------------\n",
      "Transcription:\n",
      "  Mean: 3326.2 characters\n",
      "  Median: 2850.5 characters\n",
      "  Min: 13 characters\n",
      "  Max: 15216 characters\n",
      "\n",
      "Description:\n",
      "  Mean: 140.4 characters\n",
      "  Median: 123.5 characters\n",
      "  Min: 14 characters\n",
      "  Max: 491 characters\n",
      "\n",
      "Word Count Statistics:\n",
      "----------------------------------------------------------------------\n",
      "Transcription:\n",
      "  Mean: 504.0 words\n",
      "  Median: 427.0 words\n",
      "\n",
      "Description:\n",
      "  Mean: 19.7 words\n",
      "  Median: 16.0 words\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEXT LENGTH ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calculate character lengths for both text fields\n",
    "train_df['transcription_length'] = train_df['transcription'].str.len()\n",
    "train_df['description_length'] = train_df['description'].str.len()\n",
    "\n",
    "# Calculate word counts for both text fields\n",
    "train_df['transcription_words'] = train_df['transcription'].str.split().str.len()\n",
    "train_df['description_words'] = train_df['description'].str.split().str.len()\n",
    "\n",
    "print(\"\\nCharacter Length Statistics:\")\n",
    "print(\"-\"*70)\n",
    "print(f\"Transcription:\")\n",
    "print(f\"  Mean: {train_df['transcription_length'].mean():.1f} characters\")\n",
    "print(f\"  Median: {train_df['transcription_length'].median():.1f} characters\")\n",
    "print(f\"  Min: {train_df['transcription_length'].min():.0f} characters\")\n",
    "print(f\"  Max: {train_df['transcription_length'].max():.0f} characters\")\n",
    "\n",
    "print(f\"\\nDescription:\")\n",
    "print(f\"  Mean: {train_df['description_length'].mean():.1f} characters\")\n",
    "print(f\"  Median: {train_df['description_length'].median():.1f} characters\")\n",
    "print(f\"  Min: {train_df['description_length'].min():.0f} characters\")\n",
    "print(f\"  Max: {train_df['description_length'].max():.0f} characters\")\n",
    "\n",
    "print(\"\\nWord Count Statistics:\")\n",
    "print(\"-\"*70)\n",
    "print(f\"Transcription:\")\n",
    "print(f\"  Mean: {train_df['transcription_words'].mean():.1f} words\")\n",
    "print(f\"  Median: {train_df['transcription_words'].median():.1f} words\")\n",
    "\n",
    "print(f\"\\nDescription:\")\n",
    "print(f\"  Mean: {train_df['description_words'].mean():.1f} words\")\n",
    "print(f\"  Median: {train_df['description_words'].median():.1f} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7d70a7",
   "metadata": {},
   "source": [
    "## Text Length Analysis - Calculate Statistics\n",
    "<!-- Purpose: Analyze the length of transcriptions and descriptions\n",
    "This helps us understand document sizes and choose appropriate features -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
